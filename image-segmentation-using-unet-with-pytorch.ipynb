{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nomercysagar/image-segmentation-using-unet-with-pytorch?scriptVersionId=111768749\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-22T14:36:16.066588Z","iopub.execute_input":"2022-11-22T14:36:16.067003Z","iopub.status.idle":"2022-11-22T14:36:26.709168Z","shell.execute_reply.started":"2022-11-22T14:36:16.066959Z","shell.execute_reply":"2022-11-22T14:36:26.7083Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# U-Net Original Research Paper\n### Paper Name: U-Net: Convolutional Networks for Biomedical Image Segmentation\n### Paper Link: https://arxiv.org/pdf/1505.04597.pdf","metadata":{}},{"cell_type":"markdown","source":"# Configs","metadata":{}},{"cell_type":"code","source":"class ROOTDIR:\n    train = \"../input/leaf-disease-segmentation-dataset/data/data/images\"\n    train_mask = \"../input/leaf-disease-segmentation-dataset/data/data/masks\"","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:37:43.922636Z","iopub.execute_input":"2022-11-22T14:37:43.923024Z","iopub.status.idle":"2022-11-22T14:37:43.927641Z","shell.execute_reply.started":"2022-11-22T14:37:43.922992Z","shell.execute_reply":"2022-11-22T14:37:43.926665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# General Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport zipfile\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:37:48.121426Z","iopub.execute_input":"2022-11-22T14:37:48.121778Z","iopub.status.idle":"2022-11-22T14:37:48.127171Z","shell.execute_reply.started":"2022-11-22T14:37:48.121748Z","shell.execute_reply":"2022-11-22T14:37:48.125263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Files","metadata":{}},{"cell_type":"markdown","source":"dirs = [\"../input/carvana-image-masking-challenge/train.zip\",\n        \"../input/carvana-image-masking-challenge/train_masks.zip\",\n        \"../input/carvana-image-masking-challenge/metadata.csv.zip\"]\n\nfor i in tqdm(dirs):\n    with zipfile.ZipFile(i) as z:\n        z.extractall()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-02T09:18:53.45752Z","iopub.execute_input":"2022-11-02T09:18:53.457799Z","iopub.status.idle":"2022-11-02T09:19:02.152747Z","shell.execute_reply.started":"2022-11-02T09:18:53.457764Z","shell.execute_reply":"2022-11-02T09:19:02.151708Z"}}},{"cell_type":"markdown","source":"# Working with CSV","metadata":{}},{"cell_type":"markdown","source":"df = pd.read_csv(\"./metadata.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-02T09:19:02.154243Z","iopub.execute_input":"2022-11-02T09:19:02.154686Z","iopub.status.idle":"2022-11-02T09:19:02.182903Z","shell.execute_reply.started":"2022-11-02T09:19:02.15465Z","shell.execute_reply":"2022-11-02T09:19:02.182114Z"}}},{"cell_type":"markdown","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-02T09:19:02.184163Z","iopub.execute_input":"2022-11-02T09:19:02.184586Z","iopub.status.idle":"2022-11-02T09:19:02.200323Z","shell.execute_reply.started":"2022-11-02T09:19:02.184552Z","shell.execute_reply":"2022-11-02T09:19:02.198645Z"}}},{"cell_type":"markdown","source":"# Working with Train Images and Masks","metadata":{}},{"cell_type":"code","source":"from PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:37:56.826634Z","iopub.execute_input":"2022-11-22T14:37:56.827101Z","iopub.status.idle":"2022-11-22T14:37:56.831807Z","shell.execute_reply.started":"2022-11-22T14:37:56.827062Z","shell.execute_reply":"2022-11-22T14:37:56.830615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#os.mkdir(\"masks\")\nfor imgname in os.listdir(ROOTDIR.train_mask):\n    img = Image.open('../input/leaf-disease-segmentation-dataset/data/data/masks/'+imgname) # open colour image\n    img = img.convert('L') # convert image to black and white\n    img.save('./masks/'+imgname)\n    '''img=cv2.imread('..\\\\input\\\\leaf-disease-segmentation-dataset\\\\data\\\\data\\\\masks'+imgname)\n    print(type(img))\n    img=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    img=cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n    cv2.imwrite(imgname, img)'''","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:36:52.681262Z","iopub.execute_input":"2022-11-22T14:36:52.681933Z","iopub.status.idle":"2022-11-22T14:36:52.774349Z","shell.execute_reply.started":"2022-11-22T14:36:52.681887Z","shell.execute_reply":"2022-11-22T14:36:52.773072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOTDIR.train_mask=\"./masks\"","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:38:18.042269Z","iopub.execute_input":"2022-11-22T14:38:18.042637Z","iopub.status.idle":"2022-11-22T14:38:18.046793Z","shell.execute_reply.started":"2022-11-22T14:38:18.042607Z","shell.execute_reply":"2022-11-22T14:38:18.045647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_lst = os.listdir(ROOTDIR.train) # \"./train\"\ntrain_mask_lst = os.listdir(ROOTDIR.train_mask) # \"./train_masks\"","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:38:22.011533Z","iopub.execute_input":"2022-11-22T14:38:22.011911Z","iopub.status.idle":"2022-11-22T14:38:22.02872Z","shell.execute_reply.started":"2022-11-22T14:38:22.011858Z","shell.execute_reply":"2022-11-22T14:38:22.026831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_mask_lst[:5])\nprint(train_img_lst[:5])","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:33.862433Z","iopub.execute_input":"2022-11-04T05:56:33.862798Z","iopub.status.idle":"2022-11-04T05:56:33.86784Z","shell.execute_reply.started":"2022-11-04T05:56:33.862766Z","shell.execute_reply":"2022-11-04T05:56:33.866993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_mask_lst))\nprint(len(train_img_lst))","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:34.352496Z","iopub.execute_input":"2022-11-04T05:56:34.35329Z","iopub.status.idle":"2022-11-04T05:56:34.35775Z","shell.execute_reply.started":"2022-11-04T05:56:34.353257Z","shell.execute_reply":"2022-11-04T05:56:34.356909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Sorting to make sure we get right image and right mask","metadata":{}},{"cell_type":"code","source":"sorted_train_mask_lst = sorted(train_mask_lst)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:35.192558Z","iopub.execute_input":"2022-11-04T05:56:35.192983Z","iopub.status.idle":"2022-11-04T05:56:35.19857Z","shell.execute_reply.started":"2022-11-04T05:56:35.192938Z","shell.execute_reply":"2022-11-04T05:56:35.197643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_train_img_lst = sorted(train_img_lst)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:35.482372Z","iopub.execute_input":"2022-11-04T05:56:35.483193Z","iopub.status.idle":"2022-11-04T05:56:35.487523Z","shell.execute_reply.started":"2022-11-04T05:56:35.483159Z","shell.execute_reply":"2022-11-04T05:56:35.486364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sorted_train_mask_lst[:16])\nprint(sorted_train_img_lst[:16])","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:35.682275Z","iopub.execute_input":"2022-11-04T05:56:35.682712Z","iopub.status.idle":"2022-11-04T05:56:35.688661Z","shell.execute_reply.started":"2022-11-04T05:56:35.682684Z","shell.execute_reply":"2022-11-04T05:56:35.687833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Images with their Mask\n### Making sure images and mask are paired correctly.","metadata":{}},{"cell_type":"code","source":"def show_images(imgs_lst,masks_lst,loops=2):\n    for i in range(loops):\n        img_path = os.path.join(ROOTDIR.train,imgs_lst[i])\n        mask_path = os.path.join(ROOTDIR.train_mask,masks_lst[i])\n        img = Image.open(img_path)\n        mask = Image.open(mask_path)\n        print(img_path)\n        print(img.size)\n        print(type(img))\n        plt.imshow(img)\n        plt.show()\n        print(mask_path)\n        print(mask.size)\n        plt.imshow(mask)\n        plt.show()\n        print(\"----------------------------------------------------\")\n\nshow_images(sorted_train_img_lst, sorted_train_mask_lst)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:39:02.847232Z","iopub.execute_input":"2022-11-22T14:39:02.847593Z","iopub.status.idle":"2022-11-22T14:39:02.864255Z","shell.execute_reply.started":"2022-11-22T14:39:02.847564Z","shell.execute_reply":"2022-11-22T14:39:02.863271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PyTorch Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport albumentations as A\nimport torch.optim as optim\nfrom torchvision import models\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom albumentations.pytorch import ToTensorV2 \nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:39:45.552613Z","iopub.execute_input":"2022-11-22T14:39:45.552998Z","iopub.status.idle":"2022-11-22T14:39:48.938434Z","shell.execute_reply.started":"2022-11-22T14:39:45.552962Z","shell.execute_reply":"2022-11-22T14:39:48.937533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PyTorch Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    split_pct = 0.2\n    learning_rate = 3e-4\n    batch_size = 4\n    epochs = 30","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:39:54.121611Z","iopub.execute_input":"2022-11-22T14:39:54.12252Z","iopub.status.idle":"2022-11-22T14:39:54.191394Z","shell.execute_reply.started":"2022-11-22T14:39:54.122483Z","shell.execute_reply":"2022-11-22T14:39:54.190503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 123\nnp.random.seed(seed)\ntorch.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:39:59.135777Z","iopub.execute_input":"2022-11-22T14:39:59.136522Z","iopub.status.idle":"2022-11-22T14:39:59.148408Z","shell.execute_reply.started":"2022-11-22T14:39:59.136485Z","shell.execute_reply":"2022-11-22T14:39:59.147563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.device","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:40:03.805504Z","iopub.execute_input":"2022-11-22T14:40:03.805871Z","iopub.status.idle":"2022-11-22T14:40:03.811864Z","shell.execute_reply.started":"2022-11-22T14:40:03.805839Z","shell.execute_reply":"2022-11-22T14:40:03.811052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Working with data","metadata":{}},{"cell_type":"markdown","source":"### Shuffling the data.","metadata":{}},{"cell_type":"code","source":"#permuted_train_img_lst = np.random.permutation(np.array(sorted_train_img_lst))\n#permuted_train_mask_lst = [x.replace(\".jpg\", \"_mask.gif\") for x in permuted_train_img_lst]\nprint(sorted_train_img_lst[:5])\nprint(sorted_train_mask_lst[:5])","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:38.492407Z","iopub.execute_input":"2022-11-04T05:56:38.492722Z","iopub.status.idle":"2022-11-04T05:56:38.497862Z","shell.execute_reply.started":"2022-11-04T05:56:38.492695Z","shell.execute_reply":"2022-11-04T05:56:38.496819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(sorted_train_img_lst,sorted_train_mask_lst)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:38.732551Z","iopub.execute_input":"2022-11-04T05:56:38.734763Z","iopub.status.idle":"2022-11-04T05:56:39.526785Z","shell.execute_reply.started":"2022-11-04T05:56:38.73472Z","shell.execute_reply":"2022-11-04T05:56:39.525919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting into Training and Validation","metadata":{}},{"cell_type":"code","source":"length = len(sorted_train_img_lst)\nprint(length*0.2) # convert this to int","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:39.528441Z","iopub.execute_input":"2022-11-04T05:56:39.528879Z","iopub.status.idle":"2022-11-04T05:56:39.534208Z","shell.execute_reply.started":"2022-11-04T05:56:39.528842Z","shell.execute_reply":"2022-11-04T05:56:39.533197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images_list = sorted_train_img_lst[int(CFG.split_pct*len(sorted_train_img_lst)) :]\ntrain_masks_list = sorted_train_mask_lst[int(CFG.split_pct*len(sorted_train_mask_lst)) :]\nprint(len(train_masks_list))\n\nval_images_list = sorted_train_img_lst[: int(CFG.split_pct*len(sorted_train_img_lst))]\nval_masks_list = sorted_train_mask_lst[: int(CFG.split_pct*len(sorted_train_mask_lst))]\nprint(len(val_masks_list))\n\n# 4071+1017=5088 (split includes all items)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:39.535783Z","iopub.execute_input":"2022-11-04T05:56:39.536224Z","iopub.status.idle":"2022-11-04T05:56:39.544111Z","shell.execute_reply.started":"2022-11-04T05:56:39.536187Z","shell.execute_reply":"2022-11-04T05:56:39.543336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Train Dataset","metadata":{}},{"cell_type":"code","source":"show_images(train_images_list,train_masks_list)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:39.563395Z","iopub.execute_input":"2022-11-04T05:56:39.563668Z","iopub.status.idle":"2022-11-04T05:56:40.306771Z","shell.execute_reply.started":"2022-11-04T05:56:39.563644Z","shell.execute_reply":"2022-11-04T05:56:40.305678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Validation Dataset","metadata":{}},{"cell_type":"code","source":"show_images(val_images_list,val_masks_list)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:40.308335Z","iopub.execute_input":"2022-11-04T05:56:40.308755Z","iopub.status.idle":"2022-11-04T05:56:41.097102Z","shell.execute_reply.started":"2022-11-04T05:56:40.30872Z","shell.execute_reply":"2022-11-04T05:56:41.096004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class CarvanaDataset(Dataset):\n    def __init__(self,img_list,mask_list,transform=None):\n        self.img_list = img_list\n        self.mask_list = mask_list\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.img_list)\n    \n    def __getitem__(self,index):\n        img_path = os.path.join(ROOTDIR.train,self.img_list[index])\n        mask_path = os.path.join(ROOTDIR.train_mask,self.mask_list[index])\n        img = Image.open(img_path)\n        mask = Image.open(mask_path)\n        img = np.array(img)\n        mask = np.array(mask)\n        mask[mask==255.0] = 1.0\n        #img_mask_dict = {\"image\": img, \"mask\": mask}\n        \n        if self.transform:\n            augmentation = self.transform(image=img, mask=mask)\n            img = augmentation[\"image\"]\n            mask = augmentation[\"mask\"]\n            mask = torch.unsqueeze(mask,0)\n            #transformations = self.transform(image=img, mask=mask)\n            #img = transformations[\"image\"]\n            #mask = transformations[\"mask\"]\n            \n        return img,mask","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:40:45.78885Z","iopub.execute_input":"2022-11-22T14:40:45.789692Z","iopub.status.idle":"2022-11-22T14:40:45.797528Z","shell.execute_reply.started":"2022-11-22T14:40:45.789656Z","shell.execute_reply":"2022-11-22T14:40:45.796384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose([A.Resize(572,572), \n                             A.Rotate(limit=15,p=0.1),\n                             A.HorizontalFlip(p=0.5),\n                             A.Normalize(mean=(0,0,0),std=(1,1,1),max_pixel_value=255),\n                             ToTensorV2()])\n\nval_transform = A.Compose([A.Resize(572,572),\n                           A.Normalize(mean=(0,0,0),std=(1,1,1),max_pixel_value=255),\n                           ToTensorV2()])","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:40:56.905624Z","iopub.execute_input":"2022-11-22T14:40:56.906013Z","iopub.status.idle":"2022-11-22T14:40:56.912535Z","shell.execute_reply.started":"2022-11-22T14:40:56.90598Z","shell.execute_reply":"2022-11-22T14:40:56.911679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CarvanaDataset(train_images_list, train_masks_list, transform = train_transform)\nval_dataset = CarvanaDataset(val_images_list, val_masks_list, transform = train_transform)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:41.121528Z","iopub.execute_input":"2022-11-04T05:56:41.121879Z","iopub.status.idle":"2022-11-04T05:56:41.12854Z","shell.execute_reply.started":"2022-11-04T05:56:41.121846Z","shell.execute_reply":"2022-11-04T05:56:41.12797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 200\nimg,mask = train_dataset[idx]","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:43.393225Z","iopub.execute_input":"2022-11-04T05:56:43.393589Z","iopub.status.idle":"2022-11-04T05:56:43.412109Z","shell.execute_reply.started":"2022-11-04T05:56:43.39356Z","shell.execute_reply":"2022-11-04T05:56:43.411343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:43.983475Z","iopub.execute_input":"2022-11-04T05:56:43.984124Z","iopub.status.idle":"2022-11-04T05:56:43.991884Z","shell.execute_reply.started":"2022-11-04T05:56:43.984088Z","shell.execute_reply":"2022-11-04T05:56:43.990588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.max()","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:44.182352Z","iopub.execute_input":"2022-11-04T05:56:44.182744Z","iopub.status.idle":"2022-11-04T05:56:44.191065Z","shell.execute_reply.started":"2022-11-04T05:56:44.18271Z","shell.execute_reply":"2022-11-04T05:56:44.190105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_single_img(img,mask,index=None,train=True):\n    if index:\n        if train:\n            img,mask = train_dataset[index]\n        else:\n            img,mask = val_dataset[index]\n    plt.imshow(img.permute(1,2,0),cmap=\"gray\")  # Convert (3, 572, 572) -> (572, 572, 3)\n    plt.show()\n    plt.imshow(mask.permute(1,2,0), cmap=\"gray\")  # Convert (1, 572, 572) -> (572, 572, 1)\n    print(mask.shape)\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:41:22.754869Z","iopub.execute_input":"2022-11-22T14:41:22.755569Z","iopub.status.idle":"2022-11-22T14:41:22.762716Z","shell.execute_reply.started":"2022-11-22T14:41:22.755531Z","shell.execute_reply":"2022-11-22T14:41:22.761031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"---------------Train---------------\")\nshow_single_img(img,mask,index=15,train=False)\nprint(\"---------------Validation---------------\")\nshow_single_img(img,mask,index=15,train=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:45.113536Z","iopub.execute_input":"2022-11-04T05:56:45.113869Z","iopub.status.idle":"2022-11-04T05:56:46.03179Z","shell.execute_reply.started":"2022-11-04T05:56:45.11384Z","shell.execute_reply":"2022-11-04T05:56:46.030862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset,batch_size=CFG.batch_size,shuffle=True)\nval_dataloader = DataLoader(val_dataset,batch_size=CFG.batch_size,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:46.855528Z","iopub.execute_input":"2022-11-04T05:56:46.856224Z","iopub.status.idle":"2022-11-04T05:56:46.861705Z","shell.execute_reply.started":"2022-11-04T05:56:46.856185Z","shell.execute_reply":"2022-11-04T05:56:46.860803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = iter(train_dataloader)\nimg,mask = a.next()\nprint(img.shape,mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:47.262109Z","iopub.execute_input":"2022-11-04T05:56:47.262444Z","iopub.status.idle":"2022-11-04T05:56:47.332282Z","shell.execute_reply.started":"2022-11-04T05:56:47.262415Z","shell.execute_reply":"2022-11-04T05:56:47.33144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utility Functions","metadata":{}},{"cell_type":"code","source":"def double_conv(in_ch, out_ch):\n    conv = nn.Sequential(\n        nn.Conv2d(in_channels=in_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n        nn.BatchNorm2d(out_ch),                                                            \n        nn.ReLU(inplace=True),\n        nn.Conv2d(in_channels=out_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1), \n        nn.BatchNorm2d(out_ch),                                                            \n        nn.ReLU(inplace=True)\n    )\n    \n    return conv\n\n#def cropper(og_tensor, target_tensor):\n#    og_shape = og_tensor.shape[2]\n#    target_shape = target_tensor.shape[2]\n#    delta = (og_shape - target_shape) // 2\n#    cropped_og_tensor = og_tensor[:,:,delta:og_shape-delta,delta:og_shape-delta]\n#    return cropped_og_tensor\n \n    \ndef padder(left_tensor, right_tensor): \n    # left_tensor is the tensor on the encoder side of UNET\n    # right_tensor is the tensor on the decoder side  of the UNET\n    \n    if left_tensor.shape != right_tensor.shape:\n        padded = torch.zeros(left_tensor.shape)\n        padded[:, :, :right_tensor.shape[2], :right_tensor.shape[3]] = right_tensor\n        return padded.to(CFG.device)\n    \n    return right_tensor.to(CFG.device)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:41:43.298285Z","iopub.execute_input":"2022-11-22T14:41:43.298665Z","iopub.status.idle":"2022-11-22T14:41:43.305844Z","shell.execute_reply.started":"2022-11-22T14:41:43.298633Z","shell.execute_reply":"2022-11-22T14:41:43.304935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNET MODEL FROM SCRATCH","metadata":{}},{"cell_type":"code","source":"class UNET(nn.Module):\n    def __init__(self,in_chnls, n_classes):\n        super(UNET,self).__init__()\n        \n        self.in_chnls = in_chnls\n        self.n_classes = n_classes\n        \n        self.max_pool = nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        self.down_conv_1 = double_conv(in_ch=self.in_chnls,out_ch=64)\n        self.down_conv_2 = double_conv(in_ch=64,out_ch=128)\n        self.down_conv_3 = double_conv(in_ch=128,out_ch=256)\n        self.down_conv_4 = double_conv(in_ch=256,out_ch=512)\n        self.down_conv_5 = double_conv(in_ch=512,out_ch=1024)\n        #print(self.down_conv_1)\n        \n        self.up_conv_trans_1 = nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=2,stride=2)\n        self.up_conv_trans_2 = nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=2,stride=2)\n        self.up_conv_trans_3 = nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=2,stride=2)\n        self.up_conv_trans_4 = nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=2,stride=2)\n        \n        self.up_conv_1 = double_conv(in_ch=1024,out_ch=512)\n        self.up_conv_2 = double_conv(in_ch=512,out_ch=256)\n        self.up_conv_3 = double_conv(in_ch=256,out_ch=128)\n        self.up_conv_4 = double_conv(in_ch=128,out_ch=64)\n        \n        self.conv_1x1 = nn.Conv2d(in_channels=64,out_channels=self.n_classes,kernel_size=1,stride=1)\n        \n    def forward(self,x):\n        \n        # encoding\n        x1 = self.down_conv_1(x)\n        #print(\"X1\", x1.shape)\n        p1 = self.max_pool(x1)\n        #print(\"p1\", p1.shape)\n        x2 = self.down_conv_2(p1)\n        #print(\"X2\", x2.shape)\n        p2 = self.max_pool(x2)\n        #print(\"p2\", p2.shape)\n        x3 = self.down_conv_3(p2)\n        #print(\"X2\", x3.shape)\n        p3 = self.max_pool(x3)\n        #print(\"p3\", p3.shape)\n        x4 = self.down_conv_4(p3)\n        #print(\"X4\", x4.shape)\n        p4 = self.max_pool(x4)\n        #print(\"p4\", p4.shape)\n        x5 = self.down_conv_5(p4)\n        #print(\"X5\", x5.shape)\n        \n        # decoding\n        d1 = self.up_conv_trans_1(x5)  # up transpose convolution (\"up sampling\" as called in UNET paper)\n        pad1 = padder(x4,d1) # padding d1 to match x4 shape\n        cat1 = torch.cat([x4,pad1],dim=1) # concatenating padded d1 and x4 on channel dimension(dim 1) [batch(dim 0),channel(dim 1),height(dim 2),width(dim 3)]\n        uc1 = self.up_conv_1(cat1) # 1st up double convolution\n        \n        d2 = self.up_conv_trans_2(uc1)\n        pad2 = padder(x3,d2)\n        cat2 = torch.cat([x3,pad2],dim=1)\n        uc2 = self.up_conv_2(cat2)\n        \n        d3 = self.up_conv_trans_3(uc2)\n        pad3 = padder(x2,d3)\n        cat3 = torch.cat([x2,pad3],dim=1)\n        uc3 = self.up_conv_3(cat3)\n        \n        d4 = self.up_conv_trans_4(uc3)\n        pad4 = padder(x1,d4)\n        cat4 = torch.cat([x1,pad4],dim=1)\n        uc4 = self.up_conv_4(cat4)\n        \n        conv_1x1 = self.conv_1x1(uc4)\n        return conv_1x1\n        #print(conv_1x1.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:42:09.943037Z","iopub.execute_input":"2022-11-22T14:42:09.943426Z","iopub.status.idle":"2022-11-22T14:42:09.960565Z","shell.execute_reply.started":"2022-11-22T14:42:09.943393Z","shell.execute_reply":"2022-11-22T14:42:09.959637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and Validation","metadata":{}},{"cell_type":"markdown","source":"### Train Function\n","metadata":{}},{"cell_type":"code","source":"def train_model(model,dataloader,criterion,optimizer):\n    model.train()\n    train_running_loss = 0.0\n    for j,img_mask in enumerate(tqdm(dataloader)):\n        img = img_mask[0].float().to(CFG.device)\n        #print(\" ----- IMAGE -----\")\n        #print(img)\n        mask = img_mask[1].float().to(CFG.device)\n        #print(\" ----- MASK -----\")\n        #print(mask)\n        \n        y_pred = model(img)\n        #print(\" ----- Y PRED -----\")\n        #print(y_pred)\n        #print(\" ----- Y PRED SHAPE -----\")#\n        #print(y_pred.shape)\n        optimizer.zero_grad()\n        \n        loss = criterion(y_pred,mask)\n        \n        train_running_loss += loss.item() * CFG.batch_size\n        \n        loss.backward()\n        optimizer.step()\n        \n    train_loss = train_running_loss / (j+1)\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:50.972376Z","iopub.execute_input":"2022-11-04T05:56:50.973004Z","iopub.status.idle":"2022-11-04T05:56:50.979667Z","shell.execute_reply.started":"2022-11-04T05:56:50.97297Z","shell.execute_reply":"2022-11-04T05:56:50.978773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validation Function","metadata":{}},{"cell_type":"code","source":"def val_model(model,dataloader,criterion,optimizer):\n    model.eval()\n    val_running_loss = 0\n    with torch.no_grad():\n        for j,img_mask in enumerate(tqdm(dataloader)):\n            img = img_mask[0].float().to(CFG.device)\n            mask = img_mask[1].float().to(CFG.device)\n            y_pred = model(img)\n            loss = criterion(y_pred,mask)\n            \n            val_running_loss += loss.item() * CFG.batch_size\n            \n        val_loss = val_running_loss / (j+1)\n    return val_loss","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:51.42217Z","iopub.execute_input":"2022-11-04T05:56:51.42273Z","iopub.status.idle":"2022-11-04T05:56:51.428805Z","shell.execute_reply.started":"2022-11-04T05:56:51.422701Z","shell.execute_reply":"2022-11-04T05:56:51.427776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UNET(in_chnls = 3, n_classes = 1).to(CFG.device)\noptimizer = optim.Adam(model.parameters(), lr = CFG.learning_rate)\ncriterion = nn.BCEWithLogitsLoss()\ntrain_loss_lst = []\nval_loss_lst = []  ","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:51.652308Z","iopub.execute_input":"2022-11-04T05:56:51.652706Z","iopub.status.idle":"2022-11-04T05:56:51.970963Z","shell.execute_reply.started":"2022-11-04T05:56:51.652679Z","shell.execute_reply":"2022-11-04T05:56:51.970045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train and Validation Loop","metadata":{}},{"cell_type":"code","source":"for i in tqdm(range(CFG.epochs)):\n    train_loss = train_model(model=model,dataloader=train_dataloader,criterion=criterion,optimizer=optimizer)\n    val_loss = val_model(model=model,dataloader=val_dataloader,criterion=criterion,optimizer=optimizer)\n    train_loss_lst.append(train_loss)\n    val_loss_lst.append(val_loss)\n    print(f\" Train Loss : {train_loss:.4f}\")\n    print(f\" Validation Loss : {val_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-04T05:56:52.153169Z","iopub.execute_input":"2022-11-04T05:56:52.153506Z","iopub.status.idle":"2022-11-04T07:19:42.405676Z","shell.execute_reply.started":"2022-11-04T05:56:52.153477Z","shell.execute_reply":"2022-11-04T07:19:42.404864Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and Validation Loss Plot","metadata":{}},{"cell_type":"code","source":"plt.plot(train_loss_lst, color=\"green\", label='train loss')\nplt.plot(val_loss_lst, color=\"red\", label='validation loss')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:19:42.407585Z","iopub.execute_input":"2022-11-04T07:19:42.408221Z","iopub.status.idle":"2022-11-04T07:19:42.614426Z","shell.execute_reply.started":"2022-11-04T07:19:42.408181Z","shell.execute_reply":"2022-11-04T07:19:42.613705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model","metadata":{}},{"cell_type":"code","source":"TRAINED_FILE = \"./unet_scratch.pth\"","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:19:42.615836Z","iopub.execute_input":"2022-11-04T07:19:42.616446Z","iopub.status.idle":"2022-11-04T07:19:42.620081Z","shell.execute_reply.started":"2022-11-04T07:19:42.61641Z","shell.execute_reply":"2022-11-04T07:19:42.619339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), TRAINED_FILE)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:04.136765Z","iopub.execute_input":"2022-11-04T07:20:04.137616Z","iopub.status.idle":"2022-11-04T07:20:04.376067Z","shell.execute_reply.started":"2022-11-04T07:20:04.137579Z","shell.execute_reply":"2022-11-04T07:20:04.375225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(TRAINED_FILE)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:22.027555Z","iopub.execute_input":"2022-11-04T07:20:22.027915Z","iopub.status.idle":"2022-11-04T07:20:22.034266Z","shell.execute_reply.started":"2022-11-04T07:20:22.027886Z","shell.execute_reply":"2022-11-04T07:20:22.033391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"trained_model = UNET(in_chnls = 3, n_classes = 1)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:28.376963Z","iopub.execute_input":"2022-11-04T07:20:28.377633Z","iopub.status.idle":"2022-11-04T07:20:28.754797Z","shell.execute_reply.started":"2022-11-04T07:20:28.377597Z","shell.execute_reply":"2022-11-04T07:20:28.753887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#UNET_TRAINED = \"../input/unet-4-epoch-trained/unet_scratch.pth\"\nUNET_TRAINED = \"../input/leafdisease-unet-model/unet_scratch.pth\"","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:32.306154Z","iopub.execute_input":"2022-11-04T07:20:32.306526Z","iopub.status.idle":"2022-11-04T07:20:32.310195Z","shell.execute_reply.started":"2022-11-04T07:20:32.306497Z","shell.execute_reply":"2022-11-04T07:20:32.309426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_model.load_state_dict(torch.load(UNET_TRAINED))","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:35.025989Z","iopub.execute_input":"2022-11-04T07:20:35.02712Z","iopub.status.idle":"2022-11-04T07:20:35.168616Z","shell.execute_reply.started":"2022-11-04T07:20:35.027077Z","shell.execute_reply":"2022-11-04T07:20:35.167723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_model = trained_model.to(\"cuda\")\ntrained_model.eval()\n","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:36.546314Z","iopub.execute_input":"2022-11-04T07:20:36.547356Z","iopub.status.idle":"2022-11-04T07:20:36.590559Z","shell.execute_reply.started":"2022-11-04T07:20:36.547306Z","shell.execute_reply":"2022-11-04T07:20:36.589748Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#img_path = \"../input/carvana-image-masking-challenge/29bb3ece3180_11.jpg\"\nimg_path = \"../input/leaf-disease-segmentation-dataset/data/data/images/00028.jpg\"\nimg = cv2.imread(img_path)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:45.977394Z","iopub.execute_input":"2022-11-04T07:20:45.977753Z","iopub.status.idle":"2022-11-04T07:20:46.013834Z","shell.execute_reply.started":"2022-11-04T07:20:45.977722Z","shell.execute_reply":"2022-11-04T07:20:46.013081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:48.956143Z","iopub.execute_input":"2022-11-04T07:20:48.956512Z","iopub.status.idle":"2022-11-04T07:20:49.368436Z","shell.execute_reply.started":"2022-11-04T07:20:48.956481Z","shell.execute_reply":"2022-11-04T07:20:49.365173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transform = A.Compose([A.Resize(572,572),\n                           A.Normalize(mean=(0,0,0),std=(1,1,1),max_pixel_value=255),\n                           ToTensorV2()])","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:56.101455Z","iopub.execute_input":"2022-11-04T07:20:56.101824Z","iopub.status.idle":"2022-11-04T07:20:56.106815Z","shell.execute_reply.started":"2022-11-04T07:20:56.101791Z","shell.execute_reply":"2022-11-04T07:20:56.105917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image = test_transform(image = img)\n\nprint(test_image)\n\nprint(test_image[\"image\"].dtype)\nprint(test_image[\"image\"].shape)\n\nimg = test_image[\"image\"].unsqueeze(0)\nprint(img.shape)\n\nimg = img.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:57.536312Z","iopub.execute_input":"2022-11-04T07:20:57.536673Z","iopub.status.idle":"2022-11-04T07:20:57.556885Z","shell.execute_reply.started":"2022-11-04T07:20:57.536644Z","shell.execute_reply":"2022-11-04T07:20:57.555988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = trained_model(img)\npred.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:20:59.685991Z","iopub.execute_input":"2022-11-04T07:20:59.68636Z","iopub.status.idle":"2022-11-04T07:20:59.741123Z","shell.execute_reply.started":"2022-11-04T07:20:59.686329Z","shell.execute_reply":"2022-11-04T07:20:59.740188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = pred.squeeze(0).cpu().detach().numpy()\nprint(mask.shape)\nmask = mask.transpose(1,2,0)\nprint(mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:21:01.236063Z","iopub.execute_input":"2022-11-04T07:21:01.236419Z","iopub.status.idle":"2022-11-04T07:21:01.242738Z","shell.execute_reply.started":"2022-11-04T07:21:01.236389Z","shell.execute_reply":"2022-11-04T07:21:01.241821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_test_img = test_image[\"image\"].cpu().detach().numpy()\nprint(display_test_img.shape)\ndisplay_test_img = display_test_img.transpose(1,2,0)\ndisplay_test_img.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:21:02.617656Z","iopub.execute_input":"2022-11-04T07:21:02.618121Z","iopub.status.idle":"2022-11-04T07:21:02.626039Z","shell.execute_reply.started":"2022-11-04T07:21:02.618081Z","shell.execute_reply":"2022-11-04T07:21:02.624975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask[mask < 0]=0\nmask[mask > 0]=1","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:21:03.542009Z","iopub.execute_input":"2022-11-04T07:21:03.542517Z","iopub.status.idle":"2022-11-04T07:21:03.549336Z","shell.execute_reply.started":"2022-11-04T07:21:03.54239Z","shell.execute_reply":"2022-11-04T07:21:03.548311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"-------Original Image-------\")\nplt.imshow(display_test_img, cmap=\"gray\")\nplt.show()\nprint(\"-------Image Mask-------\")\nplt.imshow(mask,cmap=\"gray\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-04T07:21:04.932319Z","iopub.execute_input":"2022-11-04T07:21:04.932703Z","iopub.status.idle":"2022-11-04T07:21:05.375718Z","shell.execute_reply.started":"2022-11-04T07:21:04.932673Z","shell.execute_reply":"2022-11-04T07:21:05.374801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **webapp using streamlit**","metadata":{}},{"cell_type":"code","source":"!pip install streamlit\n!pip install pyngrok===4.1.1\nfrom pyngrok import ngrok","metadata":{"execution":{"iopub.status.busy":"2022-11-22T14:29:07.283139Z","iopub.execute_input":"2022-11-22T14:29:07.283474Z","iopub.status.idle":"2022-11-22T14:29:33.791416Z","shell.execute_reply.started":"2022-11-22T14:29:07.283445Z","shell.execute_reply":"2022-11-22T14:29:33.790316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile frontend.py\n\nimport streamlit as st\n\n\ndef detect(img_path):\n    img = cv2.imread(img_path)\n    test_transform = A.Compose([A.Resize(572,572), A.Normalize(mean=(0,0,0),std=(1,1,1),max_pixel_value=255), ToTensorV2()])\n    test_image = test_transform(image = img)\n    img = test_image[\"image\"].unsqueeze(0)\n    img = img.to(\"cuda\")\n    pred = trained_model(img)\n    mask = pred.squeeze(0).cpu().detach().numpy()\n    mask = mask.transpose(1,2,0)\n    mask[mask < 0]=0\n    mask[mask > 0]=1\n    cv2.imwrite(mask, \"result.jpg\")\n    return True\n\ntrained_model = UNET(in_chnls = 3, n_classes = 1)\nUNET_TRAINED = \"../input/leafdisease-unet-model/unet_scratch.pth\"\ntrained_model.load_state_dict(torch.load(UNET_TRAINED))\n#model = pkl.load(open(\"../input/leafdisease-unet-model/unet_scratch.pth\", \"rb\"))\n\nst.title(\"LEAF DISEASE DETECTION\")\nst.subheader(\"Leaf disease detection is used to detect the area of leaf in the image that is being infected\")\n\nst.markdown(\"**************\")\nst.title(\"Identify Disease\")\nimagefile = st.file_uploader(\"select an image containing any type of leaf\", type=([\"jpg\", \"png\", \"jpeg\"]))\nif imagefile is not None:\n    from pathlib import Path\n    path = Path(imagefile.name)\nelse:\n    path = None\nif st.button(\"Start Detection\"):\n    success = detect(path)\n    if success:\n        st.success(\"Image saved with detected disease\")\n    #st.image(imagefile, use_column_width=True, clamp=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-22T15:40:35.951301Z","iopub.execute_input":"2022-11-22T15:40:35.951659Z","iopub.status.idle":"2022-11-22T15:40:35.957959Z","shell.execute_reply.started":"2022-11-22T15:40:35.95163Z","shell.execute_reply":"2022-11-22T15:40:35.95705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nohup streamlit run frontend.py &\nurl = ngrok.connect(port='8501')\nurl","metadata":{"execution":{"iopub.status.busy":"2022-11-22T15:40:45.04816Z","iopub.execute_input":"2022-11-22T15:40:45.049137Z","iopub.status.idle":"2022-11-22T15:40:45.067915Z","shell.execute_reply.started":"2022-11-22T15:40:45.049101Z","shell.execute_reply":"2022-11-22T15:40:45.066929Z"},"trusted":true},"execution_count":null,"outputs":[]}]}